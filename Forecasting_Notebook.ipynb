{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":85723,"databundleVersionId":10652996,"sourceType":"competition"}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/diwakarsehgal/new-sol?scriptVersionId=220076579\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:01:24.892525Z","iopub.execute_input":"2025-01-31T13:01:24.892826Z","iopub.status.idle":"2025-01-31T13:01:30.434999Z","shell.execute_reply.started":"2025-01-31T13:01:24.892801Z","shell.execute_reply":"2025-01-31T13:01:30.434137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load data\ndata = pd.read_csv(\"/kaggle/input/playground-series-s5e1/train.csv\")  # Replace with actual file path\n\n# Process Date Column\ndata['date'] = pd.to_datetime(data['date'])\ndata['year'] = data['date'].dt.year\ndata['month'] = data['date'].dt.month\ndata['day'] = data['date'].dt.day\ndata['day_of_week'] = data['date'].dt.weekday\ndata['is_weekend'] = (data['day_of_week'] >= 5).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:01:30.436331Z","iopub.execute_input":"2025-01-31T13:01:30.436828Z","iopub.status.idle":"2025-01-31T13:01:30.891255Z","shell.execute_reply.started":"2025-01-31T13:01:30.436804Z","shell.execute_reply":"2025-01-31T13:01:30.890246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.drop(columns=['date'], inplace=True)  # Drop original date column","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:01:30.89328Z","iopub.execute_input":"2025-01-31T13:01:30.893619Z","iopub.status.idle":"2025-01-31T13:01:30.91769Z","shell.execute_reply.started":"2025-01-31T13:01:30.893595Z","shell.execute_reply":"2025-01-31T13:01:30.916818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encode Categorical Features\nfor col in ['country', 'store', 'product']:\n    data[col] = data[col].astype(str)\n    data[col + '_freq'] = data[col].map(data[col].value_counts() / len(data))  # Frequency Encoding\n    data[col] = LabelEncoder().fit_transform(data[col])  # Label Encoding\n\n# Split into training and missing data\ntrain_data = data[data['num_sold'].notna()]\nmissing_data = data[data['num_sold'].isna()].drop(columns=['num_sold'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:01:30.919153Z","iopub.execute_input":"2025-01-31T13:01:30.919504Z","iopub.status.idle":"2025-01-31T13:01:31.168949Z","shell.execute_reply.started":"2025-01-31T13:01:30.919469Z","shell.execute_reply":"2025-01-31T13:01:31.16787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train-Test Split\nX = train_data.drop(columns=['num_sold'])\ny = train_data['num_sold']\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:01:31.170029Z","iopub.execute_input":"2025-01-31T13:01:31.170374Z","iopub.status.idle":"2025-01-31T13:01:31.246717Z","shell.execute_reply.started":"2025-01-31T13:01:31.170341Z","shell.execute_reply":"2025-01-31T13:01:31.245952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train LightGBM Model\nparams = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'boosting_type': 'gbdt',\n    'learning_rate': 0.05,\n    'num_leaves': 31,\n    'n_estimators': 500,\n}\n\nmodel = lgb.LGBMRegressor(**params)\nmodel.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(50)], categorical_feature=['country', 'store', 'product'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:01:31.24759Z","iopub.execute_input":"2025-01-31T13:01:31.247901Z","iopub.status.idle":"2025-01-31T13:01:35.041837Z","shell.execute_reply.started":"2025-01-31T13:01:31.247862Z","shell.execute_reply":"2025-01-31T13:01:35.040967Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict missing num_sold values\nmissing_data['num_sold'] = model.predict(missing_data)\ndata.loc[data['num_sold'].isna(), 'num_sold'] = missing_data['num_sold']\n\n# Train Final Model on Full Data\nX_final = data.drop(columns=['num_sold'])\ny_final = data['num_sold']\n# Define model parameters\nlgb_params = {'objective': 'regression', 'metric': 'rmse', 'boosting_type': 'gbdt', 'num_leaves': 31, 'learning_rate': 0.05, 'feature_fraction': 0.9}\nxgb_params = {'objective': 'reg:squarederror', 'max_depth': 5, 'learning_rate': 0.05, 'n_estimators': 100}\n\n# Initialize models\nlgb_model = lgb.LGBMRegressor(**lgb_params)\nxgb_model = xgb.XGBRegressor(**xgb_params)\n\n# Train models\nlgb_model.fit(X_final, y_final, categorical_feature=['country', 'store', 'product'])\nxgb_model.fit(X_final, y_final)\n\n# Make predictions using the base models on the validation set\nlgb_valid_preds = lgb_model.predict(X_final)\nxgb_valid_preds = xgb_model.predict(X_final)\n\n# Stack the predictions from the base models (stacked as features for meta-model)\nstacked_preds = np.column_stack((lgb_valid_preds, xgb_valid_preds))\n\n# Train the meta-model (Linear Regression in this case) on the stacked predictions\nmeta_model = LinearRegression()\nmeta_model.fit(stacked_preds, y_final)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:01:35.042792Z","iopub.execute_input":"2025-01-31T13:01:35.043162Z","iopub.status.idle":"2025-01-31T13:01:38.138314Z","shell.execute_reply.started":"2025-01-31T13:01:35.04313Z","shell.execute_reply":"2025-01-31T13:01:38.137358Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict on Test Data\ntest_data = pd.read_csv(\"/kaggle/input/playground-series-s5e1/test.csv\")  # Replace with actual test file\ntest_data['date'] = pd.to_datetime(test_data['date'])\ntest_data['year'] = test_data['date'].dt.year\ntest_data['month'] = test_data['date'].dt.month\ntest_data['day'] = test_data['date'].dt.day\ntest_data['day_of_week'] = test_data['date'].dt.weekday\ntest_data['is_weekend'] = (test_data['day_of_week'] >= 5).astype(int)\ntest_data.drop(columns=['date'], inplace=True)\n\nfor col in ['country', 'store', 'product']:\n    test_data[col] = test_data[col].astype(str)\n    test_data[col + '_freq'] = test_data[col].map(data[col].value_counts() / len(data))\n    test_data[col] = LabelEncoder().fit_transform(test_data[col])\n\n# Make predictions using each model\nlgb_preds = lgb_model.predict(test_data)\nxgb_preds = xgb_model.predict(test_data)\n\n# Stack test predictions\nstacked_test_preds = np.column_stack((lgb_preds, xgb_preds))\n\n# Meta-model makes the final prediction\nfinal_preds = meta_model.predict(stacked_test_preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:01:38.140434Z","iopub.execute_input":"2025-01-31T13:01:38.140719Z","iopub.status.idle":"2025-01-31T13:01:38.876933Z","shell.execute_reply.started":"2025-01-31T13:01:38.140694Z","shell.execute_reply":"2025-01-31T13:01:38.87615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save Submission\nsubmission = pd.DataFrame({'id': test_data['id'], 'num_sold': final_preds})\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file saved as submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:01:38.877869Z","iopub.execute_input":"2025-01-31T13:01:38.878215Z","iopub.status.idle":"2025-01-31T13:01:39.069761Z","shell.execute_reply.started":"2025-01-31T13:01:38.878189Z","shell.execute_reply":"2025-01-31T13:01:39.06893Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:01:39.070623Z","iopub.execute_input":"2025-01-31T13:01:39.070866Z","iopub.status.idle":"2025-01-31T13:01:39.080404Z","shell.execute_reply.started":"2025-01-31T13:01:39.070844Z","shell.execute_reply":"2025-01-31T13:01:39.079429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}